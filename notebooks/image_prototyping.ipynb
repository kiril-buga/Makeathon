{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-19T15:08:49.240783Z",
     "start_time": "2024-10-19T15:08:49.223980Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "# Import Environment Variables\n",
    "def set_tokens():\n",
    "    global HUGGINGFACEHUB_API_TOKEN\n",
    "    global GROQ_API_KEY\n",
    "    load_dotenv()\n",
    "    if os.getenv(\"HUGGINGFACEHUB_API_TOKEN\") is not None:\n",
    "        HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "        print(f\"Token is added\")\n",
    "    if os.getenv(\"GROQ_API_KEY\") is not None:\n",
    "        GROQ_API_KEY = os.environ[\"GROQ_API_KEY\"]\n",
    "    if (os.getenv(\"AZURE_OPENAI_ENDPOINT\") is not None\n",
    "            or os.getenv(\"AZURE_OPENAI_API_KEY\") is not None):\n",
    "        AZURE_OPENAI_ENDPOINT = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "        AZUER_OPENAI_API_KEY = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "    else:\n",
    "        raise Exception(\"No API Token Provided!\")\n",
    "\n",
    "\n",
    "set_tokens()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is added\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Image assessment",
   "id": "548387b978bae76a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:20:38.932070Z",
     "start_time": "2024-10-19T16:20:30.178634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import base64\n",
    "from IPython.display import Image\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from functions import use_huggingface_endpoint\n",
    "\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "def get_image_caption2(image_path):\n",
    "    \"\"\"Generates a short caption for the provided image....\"\"\"\n",
    "\n",
    "    encoded_image = encode_image(image_path)\n",
    "\n",
    "    model_name = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "    prompt = [\n",
    "        AIMessage(content=\"You are a bot that is good at analyzing images.\"),\n",
    "        HumanMessage(content=[\n",
    "            {\"type\": \"text\", \"text\": \"Describe the contents of this image.\"},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image;base64,{encoded_image}\"\n",
    "                },\n",
    "            },\n",
    "        ])\n",
    "    ]\n",
    "\n",
    "    llm = use_huggingface_endpoint(model_name, 0.3)\n",
    "    max_new_tokens = 1024\n",
    "\n",
    "    response = llm.bind(max_tokens=max_new_tokens).invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "\n",
    "image_path = \"../data/example_aircraft.png\"\n",
    "Image(image_path)\n",
    "get_image_caption2(image_path)"
   ],
   "id": "e1fc5b966e593272",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is added\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The image shows a white Swiss International Air Lines passenger plane taxiing on the runway, likely preparing for takeoff. The all-white plane features red lettering reading 'SWISS' on its side with a red and white Swiss cross on its red tail. It has a door near its front with several windows down the side. Small wheels protrude from underneath the body of the plane, with black wheels housing those on the very front. There appears to be shadow cast on the ground in front of the plane, possibly from another plane.\\n\\nThe background features a building, likely an airport. The building is white, with tall, dark windows within. The sky is a clear blue, showing no clouds, and a forest is visible to the left of the building.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Classification and structured output",
   "id": "3b8e22f45f40502c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:32:50.655188Z",
     "start_time": "2024-10-19T16:32:49.771712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(..., enum=[\"happy\", \"neutral\", \"sad\"])\n",
    "    aggressiveness: int = Field(\n",
    "        ...,\n",
    "        description=\"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
    "        enum=[1, 2, 3, 4, 5],\n",
    "    )\n",
    "    language: str = Field(\n",
    "        ..., enum=[\"spanish\", \"english\", \"french\", \"german\", \"italian\"]\n",
    "    )\n",
    "\n",
    "\n",
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "# LLM\n",
    "llm = ChatGroq(temperature= 0, model=\"llama-3.1-8b-instant\").with_structured_output(\n",
    "    Classification\n",
    ")\n",
    "\n",
    "chain = tagging_prompt | llm"
   ],
   "id": "7a8c6abf37899e13",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T16:35:23.926112Z",
     "start_time": "2024-10-19T16:35:23.512104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input = (\"Salut, comment Ã§a va ?\")\n",
    "chain.invoke({\"input\": input})"
   ],
   "id": "f12972b9d0979c71",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='neutral', aggressiveness=1, language='french')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a43aca81bb4da1a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
